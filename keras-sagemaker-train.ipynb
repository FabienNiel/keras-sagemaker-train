{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3-us-east-1.amazonaws.com/sagemaker-sentence-classification\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket='sagemaker-intent-classification-training' # Put your s3 bucket name here\n",
    "prefix = 'input/data' # Used as part of the path in the bucket where you store data\n",
    "# customize to your bucket where you will store data\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n",
    "print(bucket_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Stopping docker: [  OK  ]\r\n",
      "Starting docker:\t.[  OK  ]\r\n",
      "Sending build context to Docker daemon  193.5kB\r",
      "\r\n",
      "Step 1/7 : FROM phenompeople/centos-python:3.6.3\n",
      " ---> e3d7d8ca4a30\n",
      "Step 2/7 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 64723ce59c04\n",
      "Step 3/7 : RUN echo ${PATH}\n",
      " ---> Using cache\n",
      " ---> 3a252e643631\n",
      "Step 4/7 : ADD requirements.txt /\n",
      " ---> Using cache\n",
      " ---> 53682fdf2481\n",
      "Step 5/7 : RUN pip3 install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 8827f8b412de\n",
      "Step 6/7 : COPY src /opt/program\n",
      " ---> Using cache\n",
      " ---> 5095a11dfb14\n",
      "Step 7/7 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 9e88bbc8432d\n",
      "Successfully built 9e88bbc8432d\n",
      "Successfully tagged sentence-classification:latest\n",
      "The push refers to repository [850021735523.dkr.ecr.us-east-1.amazonaws.com/sentence-classification]\n",
      "1a304bbdd7ed: Preparing\n",
      "51b04044f8dc: Preparing\n",
      "0776cb2696f0: Preparing\n",
      "952e0784686f: Preparing\n",
      "65c06ae44bbd: Preparing\n",
      "f194f1dd3e8f: Preparing\n",
      "ea264623c568: Preparing\n",
      "c4cd48200f79: Preparing\n",
      "bcc97fbfc9e1: Preparing\n",
      "f194f1dd3e8f: Waiting\n",
      "ea264623c568: Waiting\n",
      "c4cd48200f79: Waiting\n",
      "bcc97fbfc9e1: Waiting\n",
      "1a304bbdd7ed: Pushed\n",
      "0776cb2696f0: Pushed\n",
      "952e0784686f: Pushed\n",
      "ea264623c568: Pushed\n",
      "c4cd48200f79: Pushed\n",
      "bcc97fbfc9e1: Pushed\n",
      "65c06ae44bbd: Pushed\n",
      "f194f1dd3e8f: Pushed\n",
      "51b04044f8dc: Pushed\n",
      "latest: digest: sha256:b72a6a15f8b5b0f7519951b0729f530655a1b927a00d6e4d46224c8fb836d5d6 size: 2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=intent-classification-training\n",
    "\n",
    "chmod +x src/*\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "# On a SageMaker Notebook Instance, the docker daemon may need to be restarted in order\n",
    "# to detect your network configuration correctly.  (This is a known issue.)\n",
    "if [ -d \"/home/ec2-user/SageMaker\" ]; then\n",
    "  sudo service docker restart\n",
    "fi\n",
    "\n",
    "docker build  -t ${algorithm_name} -f Dockerfile.cpu .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data location - s3://sagemaker-sentence-classification/data\n",
      "output location - s3://sagemaker-sentence-classification/output\n"
     ]
    }
   ],
   "source": [
    "data_location = 's3://{}/data'.format(bucket)\n",
    "print(\"data location - \" + data_location)\n",
    "\n",
    "output_location = 's3://{}/output'.format(bucket)\n",
    "print(\"output location - \" + output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/intent-classification-training'.format(account, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = sage.estimator.Estimator(image_name=image, \n",
    "                                      role=role,\n",
    "                                      train_instance_count=1, \n",
    "                                      train_instance_type='ml.c5.2xlarge',\n",
    "                                      output_path=output_location,\n",
    "                                      sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-06 10:07:05 Starting - Starting the training job...\n",
      "2019-06-06 10:07:06 Starting - Launching requested ML instances......\n",
      "2019-06-06 10:08:15 Starting - Preparing the instances for training...\n",
      "2019-06-06 10:08:50 Downloading - Downloading input data\n",
      "2019-06-06 10:08:50 Training - Downloading the training image...\n",
      "2019-06-06 10:09:30 Training - Training image download completed. Training in progress...\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mScript Status - Starting\u001b[0m\n",
      "\u001b[31mReading the data\u001b[0m\n",
      "\u001b[31mException in reading data: [Errno 2] No such file or directory: '/opt/ml/input/data/training/softskillexpcrossvalidationtrnbert1.txt'\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"/opt/program/train\", line 37, in read_data\n",
      "    x = open(os.path.join(training_path, path)).readlines()\u001b[0m\n",
      "\u001b[31mFileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/input/data/training/softskillexpcrossvalidationtrnbert1.txt'\n",
      "\u001b[0m\n",
      "\u001b[31mException in reading data: [Errno 2] No such file or directory: '/opt/ml/input/data/training/softskillexpcrossvalidationtrnbert2.txt'\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"/opt/program/train\", line 37, in read_data\n",
      "    x = open(os.path.join(training_path, path)).readlines()\u001b[0m\n",
      "\u001b[31mFileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/input/data/training/softskillexpcrossvalidationtrnbert2.txt'\n",
      "\u001b[0m\n",
      "\u001b[31mException in reading data: [Errno 2] No such file or directory: '/opt/ml/input/data/training/softskillexpcrossvalidationtrnbert3.txt'\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"/opt/program/train\", line 37, in read_data\n",
      "    x = open(os.path.join(training_path, path)).readlines()\u001b[0m\n",
      "\u001b[31mFileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/input/data/training/softskillexpcrossvalidationtrnbert3.txt'\n",
      "\u001b[0m\n",
      "\u001b[31mException in reading data: [Errno 2] No such file or directory: '/opt/ml/input/data/training/softskillexpcrossvalidationtrnbert4.txt'\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"/opt/program/train\", line 37, in read_data\n",
      "    x = open(os.path.join(training_path, path)).readlines()\u001b[0m\n",
      "\u001b[31mFileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/input/data/training/softskillexpcrossvalidationtrnbert4.txt'\n",
      "\u001b[0m\n",
      "\u001b[31mFinished reading the data.\u001b[0m\n",
      "\u001b[31mRunning the test to verify data size\u001b[0m\n",
      "\u001b[31mSize of input: 11145\u001b[0m\n",
      "\u001b[31mSize of output: 11145\u001b[0m\n",
      "\u001b[31mFinished test\u001b[0m\n",
      "\u001b[31mScript Status - Finished\u001b[0m\n",
      "\n",
      "2019-06-06 10:09:41 Uploading - Uploading generated training model\n",
      "2019-06-06 10:09:41 Completed - Training job completed\n",
      "Billable seconds: 62\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
