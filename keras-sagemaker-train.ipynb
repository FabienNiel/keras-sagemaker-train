{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3-us-east-1.amazonaws.com/keras-sagemaker-train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket='keras-sagemaker-train' # Put your s3 bucket name here\n",
    "# customize to your bucket where you will store data\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n",
    "print(bucket_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Stopping docker: [  OK  ]\r\n",
      "Starting docker:\t.[  OK  ]\r\n",
      "Sending build context to Docker daemon  292.4kB\r",
      "\r\n",
      "Step 1/6 : FROM phenompeople/centos-python:3.6.3\n",
      " ---> e3d7d8ca4a30\n",
      "Step 2/6 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 6a15e41a54a0\n",
      "Step 3/6 : ADD requirements-cpu.txt /\n",
      " ---> Using cache\n",
      " ---> bfc923425753\n",
      "Step 4/6 : RUN pip3 install -r requirements-cpu.txt\n",
      " ---> Using cache\n",
      " ---> f2091e806962\n",
      "Step 5/6 : COPY src /opt/program\n",
      " ---> Using cache\n",
      " ---> 35c77aee8b92\n",
      "Step 6/6 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 894523ae9b5d\n",
      "Successfully built 894523ae9b5d\n",
      "Successfully tagged keras-sagemaker-train:latest\n",
      "The push refers to repository [850021735523.dkr.ecr.us-east-1.amazonaws.com/keras-sagemaker-train]\n",
      "fb4251a33e09: Preparing\n",
      "82dd33955078: Preparing\n",
      "b170cb69bfc9: Preparing\n",
      "952e0784686f: Preparing\n",
      "65c06ae44bbd: Preparing\n",
      "f194f1dd3e8f: Preparing\n",
      "ea264623c568: Preparing\n",
      "c4cd48200f79: Preparing\n",
      "bcc97fbfc9e1: Preparing\n",
      "f194f1dd3e8f: Waiting\n",
      "ea264623c568: Waiting\n",
      "c4cd48200f79: Waiting\n",
      "bcc97fbfc9e1: Waiting\n",
      "82dd33955078: Layer already exists\n",
      "952e0784686f: Layer already exists\n",
      "fb4251a33e09: Layer already exists\n",
      "65c06ae44bbd: Layer already exists\n",
      "b170cb69bfc9: Layer already exists\n",
      "f194f1dd3e8f: Layer already exists\n",
      "bcc97fbfc9e1: Layer already exists\n",
      "c4cd48200f79: Layer already exists\n",
      "ea264623c568: Layer already exists\n",
      "latest: digest: sha256:8a47ccd2a8c16de3254ed9e3eb415d3edf0e30f76831416d2450332911f9af9a size: 2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=keras-sagemaker-train\n",
    "\n",
    "chmod +x src/*\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "# On a SageMaker Notebook Instance, the docker daemon may need to be restarted in order\n",
    "# to detect your network configuration correctly.  (This is a known issue.)\n",
    "if [ -d \"/home/ec2-user/SageMaker\" ]; then\n",
    "  sudo service docker restart\n",
    "fi\n",
    "\n",
    "docker build  -t ${algorithm_name} -f Dockerfile.cpu .\n",
    "# Comment the above line and uncomment the below line if you wish to run on a GPU\n",
    "#docker build  -t ${algorithm_name} -f Dockerfile.gpu . \n",
    "\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data location - s3://keras-sagemaker-train/data\n",
      "output location - s3://keras-sagemaker-train/output\n"
     ]
    }
   ],
   "source": [
    "data_location = 's3://{}/data'.format(bucket)\n",
    "print(\"data location - \" + data_location)\n",
    "\n",
    "output_location = 's3://{}/output'.format(bucket)\n",
    "print(\"output location - \" + output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/keras-sagemaker-train'.format(account, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"batch_size\":128, \"epochs\":30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = sage.estimator.Estimator(image_name=image, \n",
    "                                      role=role,\n",
    "                                      train_instance_count=1, \n",
    "                                      train_instance_type='ml.c5.2xlarge',\n",
    "                                      hyperparameters=hyperparameters,\n",
    "                                      output_path=output_location,\n",
    "                                      sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-12 08:34:47 Starting - Starting the training job...\n",
      "2019-06-12 08:34:48 Starting - Launching requested ML instances......\n",
      "2019-06-12 08:35:56 Starting - Preparing the instances for training...\n",
      "2019-06-12 08:36:37 Downloading - Downloading input data\n",
      "2019-06-12 08:36:37 Training - Downloading the training image....\n",
      "\u001b[31m2019-06-12 08:37:12.363170: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[31m2019-06-12 08:37:12.392455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz\u001b[0m\n",
      "\u001b[31m2019-06-12 08:37:12.393789: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3f52440 executing computations on platform Host. Devices:\u001b[0m\n",
      "\u001b[31m2019-06-12 08:37:12.393806: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mColocations handled automatically by placer.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mUse tf.cast instead.\u001b[0m\n",
      "\u001b[31m[name: \"/device:CPU:0\"\u001b[0m\n",
      "\u001b[31mdevice_type: \"CPU\"\u001b[0m\n",
      "\u001b[31mmemory_limit: 268435456\u001b[0m\n",
      "\u001b[31mlocality {\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31mincarnation: 15199849519822416055\u001b[0m\n",
      "\u001b[31m, name: \"/device:XLA_CPU:0\"\u001b[0m\n",
      "\u001b[31mdevice_type: \"XLA_CPU\"\u001b[0m\n",
      "\u001b[31mmemory_limit: 17179869184\u001b[0m\n",
      "\u001b[31mlocality {\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31mincarnation: 9756394772387337677\u001b[0m\n",
      "\u001b[31mphysical_device_desc: \"device: XLA_CPU device\"\u001b[0m\n",
      "\u001b[31m]\u001b[0m\n",
      "\u001b[31mScript Status - Starting\u001b[0m\n",
      "\u001b[31mReading hyperparameters\u001b[0m\n",
      "\u001b[31mNumber of data samples:  10000\u001b[0m\n",
      "\u001b[31mNumber of data labels:  10000\u001b[0m\n",
      "\u001b[31mNumber of training samples:  ((8000, 784), (8000, 10))\u001b[0m\n",
      "\u001b[31mNumber of test samples:  ((2000, 784), (2000, 10))\u001b[0m\n",
      "\u001b[31mFinished reading the data.\u001b[0m\n",
      "\u001b[31mStarting the model training\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31mdense_1 (Dense)              (None, 512)               401920    \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout_1 (Dropout)          (None, 512)               0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdense_2 (Dense)              (None, 512)               262656    \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout_2 (Dropout)          (None, 512)               0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdense_3 (Dense)              (None, 10)                5130      \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 669,706\u001b[0m\n",
      "\u001b[31mTrainable params: 669,706\u001b[0m\n",
      "\u001b[31mNon-trainable params: 0\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mTrain on 8000 samples, validate on 2000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 12s - loss: 2.3028 - acc: 0.1250\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 1s - loss: 2.2917 - acc: 0.1432 \u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 2.2679 - acc: 0.1815\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 2.2333 - acc: 0.2359\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 2.1877 - acc: 0.2855\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 2.1294 - acc: 0.3243\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 2.0673 - acc: 0.3594\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 2.0019 - acc: 0.3901\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 1s 82us/step - loss: 1.9571 - acc: 0.4060 - val_loss: 1.3980 - val_acc: 0.5715\u001b[0m\n",
      "\u001b[31mEpoch 2/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 1.4336 - acc: 0.5312\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 1.4198 - acc: 0.5773\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 1.3555 - acc: 0.6052\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 1.3078 - acc: 0.6188\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 1.2659 - acc: 0.6295\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 1.2245 - acc: 0.6401\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 1.1932 - acc: 0.6480\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 1.1624 - acc: 0.6573\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 1.1432 - acc: 0.6636 - val_loss: 0.8102 - val_acc: 0.7990\u001b[0m\n",
      "\u001b[31mEpoch 3/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.8986 - acc: 0.7422\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.9105 - acc: 0.7300\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.8866 - acc: 0.7298\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.8758 - acc: 0.7300\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.8539 - acc: 0.7353\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.8388 - acc: 0.7399\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.8239 - acc: 0.7454\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.8085 - acc: 0.7482\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.8039 - acc: 0.7510 - val_loss: 0.5880 - val_acc: 0.8530\u001b[0m\n",
      "\u001b[31mEpoch 4/30\n",
      "\u001b[0m\n",
      "\u001b[31m 128/8000 [..............................] - ETA: 0s - loss: 0.6785 - acc: 0.7812\u001b[0m\n",
      "\u001b[31m1024/8000 [==>...........................] - ETA: 0s - loss: 0.6835 - acc: 0.7900\u001b[0m\n",
      "\u001b[31m1920/8000 [======>.......................] - ETA: 0s - loss: 0.6819 - acc: 0.7870\u001b[0m\n",
      "\u001b[31m2944/8000 [==========>...................] - ETA: 0s - loss: 0.6846 - acc: 0.7857\u001b[0m\n",
      "\u001b[31m3968/8000 [=============>................] - ETA: 0s - loss: 0.6725 - acc: 0.7883\u001b[0m\n",
      "\u001b[31m4992/8000 [=================>............] - ETA: 0s - loss: 0.6666 - acc: 0.7925\u001b[0m\n",
      "\u001b[31m6144/8000 [======================>.......] - ETA: 0s - loss: 0.6589 - acc: 0.7943\u001b[0m\n",
      "\u001b[31m7168/8000 [=========================>....] - ETA: 0s - loss: 0.6545 - acc: 0.7973\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.6501 - acc: 0.7989 - val_loss: 0.4686 - val_acc: 0.8845\u001b[0m\n",
      "\u001b[31mEpoch 5/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.5138 - acc: 0.8359\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.5857 - acc: 0.8229\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.5774 - acc: 0.8180\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.5626 - acc: 0.8219\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.5608 - acc: 0.8269\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.5585 - acc: 0.8264\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.5572 - acc: 0.8267\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.5475 - acc: 0.8291\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.5504 - acc: 0.8276 - val_loss: 0.3901 - val_acc: 0.8950\u001b[0m\n",
      "\u001b[31mEpoch 6/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.4608 - acc: 0.8281\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.5020 - acc: 0.8533\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.5104 - acc: 0.8456\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.5254 - acc: 0.8422\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.5105 - acc: 0.8475\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.5026 - acc: 0.8485\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.4952 - acc: 0.8484\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.4893 - acc: 0.8499\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.4896 - acc: 0.8499 - val_loss: 0.3701 - val_acc: 0.9010\u001b[0m\n",
      "\u001b[31mEpoch 7/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.4174 - acc: 0.8828\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.4700 - acc: 0.8611\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.4618 - acc: 0.8621\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.4438 - acc: 0.8647\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.4404 - acc: 0.8643\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.4465 - acc: 0.8632\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.4421 - acc: 0.8638\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.4420 - acc: 0.8625\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.4439 - acc: 0.8628 - val_loss: 0.3101 - val_acc: 0.9235\u001b[0m\n",
      "\u001b[31mEpoch 8/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.3385 - acc: 0.8984\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.3944 - acc: 0.8915\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.3887 - acc: 0.8892\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.3902 - acc: 0.8847\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.3981 - acc: 0.8814\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.4055 - acc: 0.8801\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.4080 - acc: 0.8787\u001b[0m\n",
      "\u001b[31m7168/8000 [=========================>....] - ETA: 0s - loss: 0.4063 - acc: 0.8783\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.4077 - acc: 0.8785 - val_loss: 0.2910 - val_acc: 0.9235\u001b[0m\n",
      "\u001b[31mEpoch 9/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.3488 - acc: 0.8984\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.3691 - acc: 0.8872\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.3825 - acc: 0.8801\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.3956 - acc: 0.8784\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.3967 - acc: 0.8774\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.3954 - acc: 0.8773\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.3871 - acc: 0.8790\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.3883 - acc: 0.8788\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.3831 - acc: 0.8810 - val_loss: 0.2856 - val_acc: 0.9230\u001b[0m\n",
      "\u001b[31mEpoch 10/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2812 - acc: 0.8984\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.3720 - acc: 0.8776\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.3695 - acc: 0.8837\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.3607 - acc: 0.8884\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.3666 - acc: 0.8864\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.3640 - acc: 0.8881\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.3609 - acc: 0.8892\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.3583 - acc: 0.8894\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.3567 - acc: 0.8892 - val_loss: 0.2607 - val_acc: 0.9250\u001b[0m\n",
      "\u001b[31mEpoch 11/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.4760 - acc: 0.8516\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.3265 - acc: 0.9019\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.3566 - acc: 0.8883\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.3515 - acc: 0.8891\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.3434 - acc: 0.8918\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.3461 - acc: 0.8925\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.3415 - acc: 0.8959\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.3419 - acc: 0.8965\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.3435 - acc: 0.8961 - val_loss: 0.2727 - val_acc: 0.9270\u001b[0m\n",
      "\u001b[31mEpoch 12/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.3308 - acc: 0.9375\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.3049 - acc: 0.9123\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.2975 - acc: 0.9127\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.3164 - acc: 0.9056\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.3111 - acc: 0.9070\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.3060 - acc: 0.9074\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.3148 - acc: 0.9045\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.3119 - acc: 0.9046\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.3168 - acc: 0.9045 - val_loss: 0.2487 - val_acc: 0.9280\u001b[0m\n",
      "\u001b[31mEpoch 13/30\n",
      "\u001b[0m\n",
      "\u001b[31m 128/8000 [..............................] - ETA: 0s - loss: 0.2961 - acc: 0.9062\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.3310 - acc: 0.8889\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.3075 - acc: 0.9007\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.3188 - acc: 0.8997\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.3186 - acc: 0.9015\u001b[0m\n",
      "\u001b[31m5120/8000 [==================>...........] - ETA: 0s - loss: 0.3156 - acc: 0.9008\u001b[0m\n",
      "\u001b[31m6144/8000 [======================>.......] - ETA: 0s - loss: 0.3207 - acc: 0.9001\u001b[0m\n",
      "\u001b[31m7168/8000 [=========================>....] - ETA: 0s - loss: 0.3117 - acc: 0.9039\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 57us/step - loss: 0.3030 - acc: 0.9066 - val_loss: 0.2465 - val_acc: 0.9250\u001b[0m\n",
      "\u001b[31mEpoch 14/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.3687 - acc: 0.8672\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.2920 - acc: 0.9141\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.2825 - acc: 0.9145\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.2942 - acc: 0.9097\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.3013 - acc: 0.9093\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.2965 - acc: 0.9103\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.2927 - acc: 0.9110\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.2903 - acc: 0.9116\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.2887 - acc: 0.9125 - val_loss: 0.2276 - val_acc: 0.9350\u001b[0m\n",
      "\u001b[31mEpoch 15/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.3746 - acc: 0.8906\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.2993 - acc: 0.9080\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.3040 - acc: 0.9040\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.2955 - acc: 0.9044\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.2878 - acc: 0.9072\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.2818 - acc: 0.9101\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.2711 - acc: 0.9153\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.2733 - acc: 0.9149\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.2763 - acc: 0.9145 - val_loss: 0.2297 - val_acc: 0.9330\u001b[0m\n",
      "\u001b[31mEpoch 16/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2398 - acc: 0.9219\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.2710 - acc: 0.9115\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.2847 - acc: 0.9145\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.2793 - acc: 0.9166\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.2686 - acc: 0.9174\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.2641 - acc: 0.9186\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.2662 - acc: 0.9177\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.2635 - acc: 0.9187\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.2666 - acc: 0.9177 - val_loss: 0.2112 - val_acc: 0.9400\u001b[0m\n",
      "\u001b[31mEpoch 17/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.3438 - acc: 0.9062\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.2574 - acc: 0.9149\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.2564 - acc: 0.9200\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.2354 - acc: 0.9266\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.2408 - acc: 0.9235\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.2445 - acc: 0.9242\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.2488 - acc: 0.9212\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.2517 - acc: 0.9217\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.2522 - acc: 0.9216 - val_loss: 0.1938 - val_acc: 0.9460\u001b[0m\n",
      "\u001b[31mEpoch 18/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2149 - acc: 0.9297\u001b[0m\n",
      "\u001b[31m1024/8000 [==>...........................] - ETA: 0s - loss: 0.2398 - acc: 0.9209\u001b[0m\n",
      "\u001b[31m1920/8000 [======>.......................] - ETA: 0s - loss: 0.2215 - acc: 0.9276\u001b[0m\n",
      "\u001b[31m2944/8000 [==========>...................] - ETA: 0s - loss: 0.2242 - acc: 0.9297\u001b[0m\n",
      "\u001b[31m3968/8000 [=============>................] - ETA: 0s - loss: 0.2266 - acc: 0.9294\u001b[0m\n",
      "\u001b[31m4992/8000 [=================>............] - ETA: 0s - loss: 0.2313 - acc: 0.9277\u001b[0m\n",
      "\u001b[31m6016/8000 [=====================>........] - ETA: 0s - loss: 0.2361 - acc: 0.9275\u001b[0m\n",
      "\u001b[31m7040/8000 [=========================>....] - ETA: 0s - loss: 0.2384 - acc: 0.9259\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 57us/step - loss: 0.2417 - acc: 0.9253 - val_loss: 0.1934 - val_acc: 0.9455\u001b[0m\n",
      "\u001b[31mEpoch 19/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2917 - acc: 0.9219\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.2325 - acc: 0.9219\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.2247 - acc: 0.9269\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.2352 - acc: 0.9256\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.2300 - acc: 0.9264\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.2341 - acc: 0.9263\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.2364 - acc: 0.9255\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.2278 - acc: 0.9286\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.2291 - acc: 0.9290 - val_loss: 0.1929 - val_acc: 0.9440\u001b[0m\n",
      "\u001b[31mEpoch 20/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1857 - acc: 0.9375\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.2174 - acc: 0.9280\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.2174 - acc: 0.9260\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.2145 - acc: 0.9284\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.2149 - acc: 0.9313\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.2133 - acc: 0.9324\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.2173 - acc: 0.9324\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.2208 - acc: 0.9315\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.2208 - acc: 0.9319 - val_loss: 0.1911 - val_acc: 0.9415\u001b[0m\n",
      "\u001b[31mEpoch 21/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2034 - acc: 0.9141\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.1792 - acc: 0.9410\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1941 - acc: 0.9380\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.2011 - acc: 0.9347\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.2134 - acc: 0.9332\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.2188 - acc: 0.9322\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.2144 - acc: 0.9345\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.2127 - acc: 0.9349\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.2083 - acc: 0.9364 - val_loss: 0.1894 - val_acc: 0.9455\u001b[0m\n",
      "\u001b[31mEpoch 22/30\n",
      "\u001b[0m\n",
      "\u001b[31m 128/8000 [..............................] - ETA: 0s - loss: 0.3044 - acc: 0.8984\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.2028 - acc: 0.9384\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1932 - acc: 0.9416\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.1885 - acc: 0.9431\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.1969 - acc: 0.9396\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.1945 - acc: 0.9396\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.2017 - acc: 0.9388\u001b[0m\n",
      "\u001b[31m7168/8000 [=========================>....] - ETA: 0s - loss: 0.2054 - acc: 0.9382\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.2037 - acc: 0.9377 - val_loss: 0.1893 - val_acc: 0.9455\u001b[0m\n",
      "\u001b[31mEpoch 23/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1954 - acc: 0.9375\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.1776 - acc: 0.9479\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1881 - acc: 0.9407\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.1918 - acc: 0.9406\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.1944 - acc: 0.9408\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.1907 - acc: 0.9415\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.1921 - acc: 0.9397\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.1930 - acc: 0.9386\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.1958 - acc: 0.9389 - val_loss: 0.1743 - val_acc: 0.9470\u001b[0m\n",
      "\u001b[31mEpoch 24/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.2240 - acc: 0.9297\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.1590 - acc: 0.9523\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1738 - acc: 0.9490\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.1727 - acc: 0.9466\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.1740 - acc: 0.9470\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.1746 - acc: 0.9470\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.1840 - acc: 0.9450\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.1844 - acc: 0.9442\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.1835 - acc: 0.9437 - val_loss: 0.1596 - val_acc: 0.9580\u001b[0m\n",
      "\u001b[31mEpoch 25/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1615 - acc: 0.9453\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.1877 - acc: 0.9444\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1939 - acc: 0.9435\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.1813 - acc: 0.9447\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.1805 - acc: 0.9451\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.1836 - acc: 0.9440\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.1749 - acc: 0.9464\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.1742 - acc: 0.9465\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.1775 - acc: 0.9450 - val_loss: 0.1641 - val_acc: 0.9550\u001b[0m\n",
      "\u001b[31mEpoch 26/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1425 - acc: 0.9609\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.1805 - acc: 0.9470\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1701 - acc: 0.9490\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.1801 - acc: 0.9441\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.1798 - acc: 0.9446\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.1746 - acc: 0.9463\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.1726 - acc: 0.9464\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.1709 - acc: 0.9463\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 56us/step - loss: 0.1731 - acc: 0.9451 - val_loss: 0.1744 - val_acc: 0.9490\u001b[0m\n",
      "\u001b[31mEpoch 27/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1616 - acc: 0.9609\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.1669 - acc: 0.9583\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1606 - acc: 0.9568\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.1677 - acc: 0.9544\u001b[0m\n",
      "\u001b[31m4096/8000 [==============>...............] - ETA: 0s - loss: 0.1639 - acc: 0.9526\u001b[0m\n",
      "\u001b[31m5120/8000 [==================>...........] - ETA: 0s - loss: 0.1621 - acc: 0.9506\u001b[0m\n",
      "\u001b[31m6144/8000 [======================>.......] - ETA: 0s - loss: 0.1611 - acc: 0.9505\u001b[0m\n",
      "\u001b[31m7168/8000 [=========================>....] - ETA: 0s - loss: 0.1609 - acc: 0.9498\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 57us/step - loss: 0.1621 - acc: 0.9490 - val_loss: 0.1617 - val_acc: 0.9560\u001b[0m\n",
      "\u001b[31mEpoch 28/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1343 - acc: 0.9688\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.1529 - acc: 0.9618\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1601 - acc: 0.9559\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.1513 - acc: 0.9559\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.1574 - acc: 0.9529\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.1598 - acc: 0.9520\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.1608 - acc: 0.9514\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.1621 - acc: 0.9498\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.1591 - acc: 0.9505 - val_loss: 0.1698 - val_acc: 0.9555\u001b[0m\n",
      "\u001b[31mEpoch 29/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1524 - acc: 0.9688\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.1373 - acc: 0.9557\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1538 - acc: 0.9545\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.1512 - acc: 0.9563\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.1470 - acc: 0.9564\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.1505 - acc: 0.9541\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.1484 - acc: 0.9534\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.1493 - acc: 0.9544\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.1486 - acc: 0.9550 - val_loss: 0.2031 - val_acc: 0.9425\u001b[0m\n",
      "\u001b[31mEpoch 30/30\n",
      "\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 0.1849 - acc: 0.9375\u001b[0m\n",
      "\u001b[31m1152/8000 [===>..........................] - ETA: 0s - loss: 0.1418 - acc: 0.9566\u001b[0m\n",
      "\u001b[31m2176/8000 [=======>......................] - ETA: 0s - loss: 0.1353 - acc: 0.9563\u001b[0m\n",
      "\u001b[31m3200/8000 [===========>..................] - ETA: 0s - loss: 0.1407 - acc: 0.9550\u001b[0m\n",
      "\u001b[31m4224/8000 [==============>...............] - ETA: 0s - loss: 0.1440 - acc: 0.9555\u001b[0m\n",
      "\u001b[31m5248/8000 [==================>...........] - ETA: 0s - loss: 0.1460 - acc: 0.9545\u001b[0m\n",
      "\u001b[31m6272/8000 [======================>.......] - ETA: 0s - loss: 0.1453 - acc: 0.9546\u001b[0m\n",
      "\u001b[31m7296/8000 [==========================>...] - ETA: 0s - loss: 0.1449 - acc: 0.9549\u001b[0m\n",
      "\u001b[31m8000/8000 [==============================] - 0s 55us/step - loss: 0.1447 - acc: 0.9550 - val_loss: 0.1612 - val_acc: 0.9565\u001b[0m\n",
      "\u001b[31mTest loss: 0.16121862312033772\u001b[0m\n",
      "\u001b[31mTest accuracy: 0.9565\u001b[0m\n",
      "\u001b[31mFinished training the model.\u001b[0m\n",
      "\u001b[31mFinished training the model.\u001b[0m\n",
      "\u001b[31mScript Status - Finished\u001b[0m\n",
      "\u001b[31mTotal time taken to train the model:  19.413013458251953\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-06-12 08:37:40 Uploading - Uploading generated training model\n",
      "2019-06-12 08:37:40 Completed - Training job completed\n",
      "Billable seconds: 70\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
